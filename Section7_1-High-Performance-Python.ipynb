{
 "metadata": {
  "kernelspec": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "display_name": "IPython (Python 2)",
   "language": "python",
   "name": "python2"
  },
  "name": "",
  "signature": "sha256:f6d9ffc5bf0ce91ea5bf289c1667dbee215e19ce994d4a9fddce273791800cc3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> For this lecture you will want to have installed additional Python packages:\n",
      ">\n",
      ">      sudo pip install line-profiler numexpr cython\n",
      "> \n",
      "\n",
      "# High Performance Python\n",
      "\n",
      "### Speeding up statistical computations in Python using `numexpr` and `cython`\n",
      "\n",
      "In the age of \"big data\" and sophisitcated Bayesian and statistical learning algorithms, many are interested in optimizing the performance of the high-level languages that we use to analyse data.\n",
      "\n",
      "[NumPy](http://numpy.scipy.org/) gets us part of the way there on Python:\n",
      "\n",
      "* Storage of multidimensional data\n",
      "* Efficient data access\n",
      "* Efficient in-memory storage\n",
      "* Fast methods and functions for data manipulation\n",
      "\n",
      "This gets us part of the way there, and for many applications it is sufficient. However, there is plenty of scope for improving Python's performance in situations where speed matters.\n",
      "\n",
      "Pure Python and Python with NumPy are not particularly fast. Below are some recent performance benchmarks comparing several computing languages (taken directly from the [Julia website](http://julialang.org)):\n",
      "\n",
      "\n",
      "<div class=\"figure\">\n",
      "<table class=\"benchmarks\">\n",
      "<colgroup>\n",
      "<col class=\"name\"></col>\n",
      "<col class=\"relative\" span=\"9\"></col>\n",
      "</colgroup>\n",
      "<thead>\n",
      "<tr style=\"background-color:#EEEEEE;\"><td></td><th class=\"system\">Fortran</th><th class=\"system\">Julia</th><th class=\"system\">Python</th><th class=\"system\">R</th><th class=\"system\">Matlab</th><th class=\"system\">Octave</th><th class=\"system\">Mathematica</th><th class=\"system\">JavaScript</th><th class=\"system\">Go</th></tr>\n",
      "<tr style=\"background-color:#EEEEEE;\"><td></td><td class=\"version\">gcc 4.8.1\n",
      "</td><td class=\"version\">0.2</td><td class=\"version\">2.7.3\n",
      "</td><td class=\"version\">3.0.2\n",
      "</td><td class=\"version\">R2012a\n",
      "</td><td class=\"version\">3.6.4\n",
      "</td><td class=\"version\">8.0\n",
      "</td><td class=\"version\">V8 3.7.12.22\n",
      "</td><td class=\"version\">go1\n",
      "</td></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><th>fib</th><td class=\"data\">0.26</td><td class=\"data\">0.91</td><td class=\"data\">30.37</td><td class=\"data\">411.36</td><td class=\"data\">1992.00</td><td class=\"data\">3211.81</td><td class=\"data\">64.46</td><td class=\"data\">2.18</td><td class=\"data\">1.03</td></tr>\n",
      "<tr><th>parse_int</th><td class=\"data\">5.03</td><td class=\"data\">1.60</td><td class=\"data\">13.95</td><td class=\"data\">59.40</td><td class=\"data\">1463.16</td><td class=\"data\">7109.85</td><td class=\"data\">29.54</td><td class=\"data\">2.43</td><td class=\"data\">4.79</td></tr>\n",
      "<tr><th>quicksort</th><td class=\"data\">1.11</td><td class=\"data\">1.14</td><td class=\"data\">31.98</td><td class=\"data\">524.29</td><td class=\"data\">101.84</td><td class=\"data\">1132.04</td><td class=\"data\">35.74</td><td class=\"data\">3.51</td><td class=\"data\">1.25</td></tr>\n",
      "<tr><th>mandel</th><td class=\"data\">0.86</td><td class=\"data\">0.85</td><td class=\"data\">14.19</td><td class=\"data\">106.97</td><td class=\"data\">64.58</td><td class=\"data\">316.95</td><td class=\"data\">6.07</td><td class=\"data\">3.49</td><td class=\"data\">2.36</td></tr>\n",
      "<tr><th>pi_sum</th><td class=\"data\">0.80</td><td class=\"data\">1.00</td><td class=\"data\">16.33</td><td class=\"data\">15.42</td><td class=\"data\">1.29</td><td class=\"data\">237.41</td><td class=\"data\">1.32</td><td class=\"data\">0.84</td><td class=\"data\">1.41</td></tr>\n",
      "<tr><th>rand_mat_stat</th><td class=\"data\">0.64</td><td class=\"data\">1.66</td><td class=\"data\">13.52</td><td class=\"data\">10.84</td><td class=\"data\">6.61</td><td class=\"data\">14.98</td><td class=\"data\">4.52</td><td class=\"data\">3.28</td><td class=\"data\">8.12</td></tr>\n",
      "<tr><th>rand_mat_mul</th><td class=\"data\">0.96</td><td class=\"data\">1.01</td><td class=\"data\">3.41</td><td class=\"data\">3.98</td><td class=\"data\">1.10</td><td class=\"data\">3.41</td><td class=\"data\">1.16</td><td class=\"data\">14.60</td><td class=\"data\">8.51</td></tr>\n",
      "</tbody>\n",
      "</table>\n",
      "\n",
      "<p class=\"caption\"><b>Figure:</b>\n",
      "benchmark times relative to C (smaller is better, C performance = 1.0).\n",
      "</p>\n",
      "</div>\n",
      "\n",
      "So, while fast relative to some scientific compution choices (*e.g.* R, Matlab), Python sometimes needs to be tweaked in order to make it a competitive choice for implementing modern statistical methods. We will cover two approachable ways of improving the performance of Python.\n",
      "\n",
      "\n",
      "## Profiling\n",
      "\n",
      "Before you barrel ahead and prematurely optimize your Python code, it is important to understand **why** and **where** your code is slow. This is achieved by systematically accounting for the resources that your code is using, such as memory, CPU time or data transfer. This process is broadly referred to as ***Profiling***, and it allows you to identify where the performance bottlenecks in your code lie.\n",
      "\n",
      "Here, we will concentrate on optimizing performance for **CPU-bound** problems.\n",
      "\n",
      "There are a number of tools to help you profile your code.\n",
      "\n",
      "### `time`\n",
      "\n",
      "For those of you on UNIX platforms, the built-in utility `time` can be used to assess how long your code takes to run."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!time python ../examples/abc.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The output from `time` can be interpreted as:\n",
      "\n",
      "* `real`: elapsed (wall) time\n",
      "* `user`: time spent in your code\n",
      "* `sys`: time spent in system (kernel) functions\n",
      "\n",
      "The last 2 quantities account for the cycles used by your program. The remaining `real` time is often due to waiting for information either from disk or a network connection (I/O).\n",
      "\n",
      "Python also has a `time` module (and function) that is more rudimentary; it simply returns the time, in seconds from the Epoch (1/1/1970)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "time.time()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can use this for profiling by differencing the times before and after running some code of interest:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start_time = time.time()\n",
      "reduce(lambda a,b: a*b, range(1, 100000))\n",
      "end_time = time.time()\n",
      "\n",
      "end_time - start_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note, however that it does not provide a breakdown of where the code spends its time.\n",
      "\n",
      "### IPython magic: `%timeit`, `%run` and `%prun`\n",
      "\n",
      "IPython has three built-in \"magic\" functions that are useful for profiling your code. \n",
      "\n",
      "The `%timeit` magic executes a Python statement or expressions in a loop to see how long we expect it to take for any given call. Additionally, it repeats the loop a certain number of times, and returns the best result.\n",
      "\n",
      "As an example, consider a Python implementation of the **trapezoidal rule**, a method from numerical analysis for approximating a definite integral. Specifically, it allows us to approximate:\n",
      "\n",
      "$$\\int_a^b f(x) dx$$\n",
      "\n",
      "using the approximation:\n",
      "\n",
      "$$\\int_a^b f(x) dx \\approx (b-a) \\frac{f(b) + f(a)}{2}$$\n",
      "\n",
      "Rather than use a single interval for this estimate, we break the interval down into $n$ subintervals, to obtain a more accurate approximation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def f(x):\n",
      "    return 2*x*x + 3*x + 1\n",
      "      \n",
      "def trapez(a, b, n):\n",
      "    h = (b-a)/float(n) \n",
      "    sumy = 0\n",
      "    x=a\n",
      "    \n",
      "    for i in range(n):\n",
      "        x += h\n",
      "        sumy += f(x)\n",
      "    sumy += 0.5*(f(a) + f(b))\n",
      "    return sumy*h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trapez(1, 5, 10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To confirm that this works, we can compare this to the symbolic solution, using Sympy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sympy import init_printing\n",
      "init_printing()\n",
      "import sympy as sym"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xs = sym.symbols('xs')\n",
      "\n",
      "fx = 2*xs*xs + 3*xs + 1\n",
      "\n",
      "ifx = sym.integrate(fx, (xs, 1, 5))\n",
      "ifx.evalf()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit trapez(1, 5, 10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`%timeit` tries to pick suitable values for the number of loops and repeats; these values can be overriden by specifying `-n` and `-r` values, respectively.\n",
      "\n",
      "The `%run` command with a `-p` option allows you to run complete programs under the control of the Python profiler. It writes the output to the help pane, which opens at the bottom of the page."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This code redirets pager output to a regular cell\n",
      "from __future__ import print_function\n",
      "from IPython.core import page\n",
      "page.page = print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run -p ../examples/abc.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The profiling information includes the following information:\n",
      "\n",
      "* `ncalls`: number of calls to function\n",
      "* `tottime`: total time spent in the given function (excluding time in calls to sub-functions)\n",
      "* `percall`: time per call\n",
      "* `cumtime`: cumulative time spent in this and all subfunctions \n",
      "\n",
      "We can see that most of the time in this example is spent inside of core NumPy functions and methods.\n",
      "\n",
      "The `%prun` command does a similar job for single Python expressions (like function calls)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%prun trapez(2, 6, 100000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For even more fine-grained profiling information, we can use the line profiler (`line-profiler` package) to see how long it takes each line of a function to run."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext line_profiler"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "run -i ../examples/bisection.py"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%lprun -f bisection bisection(lambda x: -2*x + 5, -10, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This output makes it clear that the biggest cost is in the repeated calling of the function $f$ for which the root is being found. If we could improve the speed of this function, it would be the easiest single way of improving the performance of the code.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Fast array expression evaluation with `numexpr`\n",
      "\n",
      "[`numexpr`](http://code.google.com/p/numexpr/) allows array expressions to be evaluated far faster that what can be achieved in Python using Numpy arrays. `numexpr` parses a string expression and optimizes and compiles the code on the fly, using a virtual machine that includes a [Just-in-time (JIT) compiler](http://en.wikipedia.org/wiki/Just-in-time_compilation). In addition, `numexpr` offers direct support for parallel multi-threaded computations, since Python's global interpreter lock is bypassed.\n",
      "\n",
      "> Python's global interpreter lock (GIL) ensures that only one thread runs in the interpreter at once. This simplifies many of the low-level activities, such as memory management, and allows for co-operative multi-tasking. But, since the currently-running thread holds onto the interpreter, it makes multi-core parallelization difficult.\n",
      "\n",
      "Part the reason Python can be slow for array calculations is that it creates temporary arrays to store intermediate results from array element calculations, which wastes memory and cache. `numexpr` handles such calculations in manageable chunks, which accellerates computation.\n",
      "\n",
      "The speedup over NumPy by using `numexpr` can be as high as 20x, but is typically in the range of 2-4x.\n",
      "\n",
      "### Example: Computing a polynomial"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "\n",
      "x = np.linspace(-1, 1, 1e7)\n",
      "\n",
      "0.25*x**3 + 0.75*x**2 - 1.5*x - 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit 0.25*x**3 + 0.75*x**2 - 1.5*x - 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numexpr as ne\n",
      "\n",
      "ne.set_num_threads(1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ne.evaluate('0.25*x**3 + 0.75*x**2 - 1.5*x - 2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit ne.evaluate('0.25*x**3 + 0.75*x**2 - 1.5*x - 2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`numexpr` actually expands the polynomial terms so that it does not need to use a transcendental function.\n",
      "\n",
      "We can achieve further gains in performance by multithreading the calculations:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ne.set_num_threads(4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit ne.evaluate('0.25*x**3 + 0.75*x**2 - 1.5*x - 2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Since the performance of processors has outpaced that of memory in the past several decades, the CPU spends a lot of time waiting for memory to give it computations; this is the ***processor-memory performance gap***.\n",
      "\n",
      "![performance gap](http://www.techdesignforums.com/practice/files/2013/02/tdf-snps-ARMcc-feb13-fig1lg.jpg)\n",
      "(graph courtesy http://www.techdesignforums.com)\n",
      "\n",
      "CPU caches are often used to make up for this difference. CPU caches are more effective when the data are optimally located in memory to take advantage of cache performance. `numexpr` does this by moving contiguous blocks of data from memory to the CPU cache, reusing them as much as possible within the cache to more quickly give the CPU access to the data.\n",
      "\n",
      "### Limitations\n",
      "\n",
      "`numexpr` only implements element-wise operations. So, `a * b` becomes:\n",
      "\n",
      "    for i in range(N):\n",
      "        c[i] = a[i] * b[i]\n",
      "\n",
      "Similarly, it cannot index other parts of arrays in the same expression:\n",
      "\n",
      "    for i in range(N):\n",
      "        c[i] = a[i-1] + a[i] * b[i]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Cython\n",
      "\n",
      "Python developers typically solve performance constraints by building Python extensions by wrapping code written in other languages (for example, SciPy contains more lines of C/C++/Fortran than Python). However, programming with the Python/C API is not straightforward for most users.\n",
      "\n",
      "Cython is a language that allows Python programmers to write fast code without having to write C/C++/Fortran directly. It looks much like Python code, but with type declarations. Cython code is translated it to C (or C++ or others), which is then compiled to create a Python extension that we can import and use. \n",
      "\n",
      "Using Cython, we can achieve speedups of several orders of magnitude, often *faster than hand-coded C code*. In addtion, Cython is compatible with core scientific programming tools like NumPy and IPython.\n",
      "\n",
      "Cython has built-in support for multicore processing.\n",
      "\n",
      "Cython is used to varying degrees by other packages in the Python scientific stack, such as pandas, sympy, scikits-learn and SciPy.\n",
      "\n",
      "### Example: Numerical integration\n",
      "\n",
      "Recall from above the function `trapez` for performing numerical integration using the trapezoidal rule. As a benchmark, let's time the execution of the pure-Python version of the trapezoidal rule:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit trapez(1, 5, 1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perhaps the easiest way to use Cython, is via the IPython `cythonmagic`, which allows us to run Cython interactively:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext cythonmagic"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "\n",
      "def f(x):\n",
      "    return 2*x*x + 3*x + 1\n",
      "\n",
      "def trapez2(a, b, n):\n",
      "    h = (b-a)/float(n) \n",
      "    sumy = 0\n",
      "    x=a\n",
      "    for i in range(n):\n",
      "        x += h\n",
      "        sumy += f(x)\n",
      "    sumy += 0.5*(f(a) + f(b))\n",
      "    return sumy*h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Cython magic is doing a lot of work for you: it compiles the code into an extension module, and loads it into the notebook. This allows us to ignore all of the compilation details of building Cython extensions. \n",
      "\n",
      "If we run `trapez2`, we can see a reasonable speedup simply by compiling it, unchanged, using Cython."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit trapez2(1, 5, 1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Under the hood, several things are happening in order to deliver this improved performance. The Cython source code is translated into C source code by `cython`. Then, this C source is compiled, using the appropriate compiler, flags and associated library files (if any), into a Python extension. This extension is then loaded by IPython into the current session.\n",
      "\n",
      "![cython flow](images/cython.png)\n",
      "\n",
      "C extensions can also be compiled manually, using a setup file. Here is an example for an extension called `dist` within a package called `probability`:\n",
      "\n",
      "    from distutils.core import setup\n",
      "    from distutils.extension import Extension\n",
      "    from Cython.Distutils import build_ext\n",
      "\n",
      "    import numpy as np\n",
      "\n",
      "    setup(\n",
      "        cmdclass = {'build_ext': build_ext},\n",
      "        ext_modules = [Extension(\"dist\", [\"probability/src/dist.pyx\"], include_dirs=[np.get_include()])]\n",
      "    )\n",
      "    \n",
      "It mainly uses machinery from a core Python package `distutils` that manages the build process.\n",
      "\n",
      "If we look at the `trapez2` function compared to the pure Python `trapez`, we see that the Cython version appears to be a lower-level function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trapez?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trapez2?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get a closer look at where Cython is improving our unchanged Python code, we can add an `--annotate` flag to the `%%cython` magic declaration:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython --annotate\n",
      "\n",
      "def f(x):\n",
      "    return 2*x*x + 3*x + 1\n",
      "      \n",
      "def trapez2(a, b, n):\n",
      "    h = (b-a)/float(n) \n",
      "    sumy = 0\n",
      "    x=a\n",
      "    for i in range(n):\n",
      "        x += h\n",
      "        sumy += f(x)\n",
      "    sumy += 0.5*(f(a) + f(b))\n",
      "    return sumy*h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the above, the line color indicates the \"typedness\" of the extension, where yellower lines are closer to Python, and therefore require calls to the Python C API, while whiter lines indicate code that is closer to pure C, hence requiring few, if any, Python API calls.\n",
      "\n",
      "If you click on a line, it unravels to show you the C code that results from the call to `cython`.\n",
      "\n",
      "The goal in speeding up code with Cython is to turn as many lines to white as we can. The easiest way to do this is to add type declarations to the Python code:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython --annotate\n",
      "\n",
      "# Add type to argument\n",
      "def ff(double x):\n",
      "    return 2*x*x + 3*x + 1\n",
      "\n",
      "# Add types to arguments\n",
      "def trapez3(double a, double b, int n):\n",
      "    # Declare types of variables\n",
      "    cdef double h, x, sumy\n",
      "    cdef int i\n",
      "    h = (b-a)/float(n) \n",
      "    sumy = 0\n",
      "    x=a\n",
      "    for i in range(n):\n",
      "        x += h\n",
      "        sumy += ff(x)\n",
      "    sumy += 0.5*(ff(a) + ff(b))\n",
      "    return sumy*h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit trapez3(1, 5, 1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This gives us a considerable speedup. The next thing we might try is to *inline* the polynomial function. By inlining, we mean that we ask the compiler to perform an inline expansion of said function; that is, it will insert a copy of the function itself wherever the function is called, instead of calling the function wherever it is defined.\n",
      "\n",
      "We do three things to the specification of `ff`:\n",
      "\n",
      "* change `def` to `cdef`\n",
      "* add a return type to the function\n",
      "* add an `inline` keyword"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython --annotate\n",
      "\n",
      "cdef inline double ff(double x):\n",
      "    return 2*x*x + 3*x + 1\n",
      "\n",
      "cpdef trapez4(double a, double b, int n):\n",
      "    cdef double h, x, sumy\n",
      "    cdef int i\n",
      "    h = (b-a)/float(n) \n",
      "    sumy = 0\n",
      "    x=a\n",
      "    for i in range(n):\n",
      "        x += h\n",
      "        sumy += ff(x)\n",
      "    sumy += 0.5*(ff(a) + ff(b))\n",
      "    return sumy*h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `cdef` keyword declares a C object. Everything that follows it is therefore specified in terms of C; we are essentially writing C, but using a subset of Python's syntax rules. So, when we are creating a function `cdef ff` it is a C function, and is not available to you in Python.\n",
      "\n",
      "`cpdef` is a hybrid declaration that creates both a C interface and a Python interface to the function.\n",
      "\n",
      "Let's see how this performs."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit trapez4(1, 5, 1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Woof! That's a big speedup, and there's not much yellow left in the annotated code. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you would like a very simple way of injecting types into your code with Cython, without modifying any of the code itelf, you can use the `@cython.locals` decorator. Note that you don't get as fast of a speedup as we have just achieved."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "import cython\n",
      "\n",
      "@cython.locals(x=cython.double)\n",
      "def f(x):\n",
      "    return 2*x*x + 3*x + 1\n",
      "     \n",
      "@cython.locals(a=cython.double, b=cython.double, n=cython.int,\n",
      "               h=cython.double, sumy=cython.double, i=cython.int,\n",
      "               x=cython.double, func=cython.double)\n",
      "def trapez5(a, b, n):\n",
      "    h = (b-a)/float(n) \n",
      "    sumy = 0\n",
      "    x=a\n",
      "    \n",
      "    for i in range(n):\n",
      "        x += h\n",
      "        sumy += f(x)\n",
      "    sumy += 0.5*(f(a) + f(b))\n",
      "    return sumy*h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit trapez5(1, 5, 1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you can stand to look at it, you can peek at all the C code that is generated by Cython just to optimize this short function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load ../examples/trapezoid.c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Due to conveneince, running Cython from IPython is a preferred way of using the language. However, if we have some legacy C/C++ code that we wish to use in Python, we can do that by writing a wrapper and calling `cython` from the terminal.\n",
      "\n",
      "Here is the C code:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load ../examples/fact.h"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "int fact(int n) {\n",
      "    if(n <= 1)\n",
      "    {\n",
      "        return 1;\n",
      "    }\n",
      "    return n * fact(n-1);\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And here is the Cython wrapper. Cython code is stored in files with a `.pyx` extension."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load ../examples/fact.c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "! cython ../examples/fact.pyx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can compile the extension."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "os.chdir('../examples')\n",
      "\n",
      "! gcc -Wall -fno-strict-aliasing -static -undefined dynamic_lookup \\\n",
      "    -bundle -arch x86_64 \\\n",
      "    -I/System/Library/Frameworks/Python.framework/Versions/2.7/include/python2.7 \\\n",
      "    -o fact.so fact.c\n",
      "    \n",
      "os.chdir('../notebooks')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cp ../examples/fact.so ."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fact\n",
      "\n",
      "fact.fact(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Using lists and arrays in Cython\n",
      "\n",
      "The above example used only scalar variables. When we have vector-valued data, we need to declare the appropriate types. Here's a simple example, using a function that calculates the Euclidean distance between two arrays:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def euclidean(x, y):\n",
      "    x = np.array(x)\n",
      "    y = np.array(y)\n",
      "    return np.sqrt(((x - y) ** 2).sum())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit euclidean(np.random.randn(10), np.random.randn(10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to get a speedup under Cython, we need to iterate over the elements of each passed array, and aggregate them manually."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython --annotate\n",
      "import cython\n",
      "cimport numpy as np\n",
      "from libc.math cimport sqrt\n",
      "\n",
      "@cython.boundscheck(False)\n",
      "@cython.wraparound(False)\n",
      "def euclidean2(np.ndarray[np.float64_t, ndim=1] x, \n",
      "               np.ndarray[np.float64_t, ndim=1] y):\n",
      "    cdef: \n",
      "        double diff\n",
      "        int i\n",
      "    diff = 0\n",
      "    for i in range(x.shape[0]):\n",
      "        diff += (x[i] - y[i])**2\n",
      "    return sqrt(diff)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit euclidean2(np.random.randn(10), np.random.randn(10))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The decorators for `trapez5` are **compiler directives** that alter the behavior of Cython code. Setting `boundscheck` to False removes boundary checking for indexing operations, forcing us to ensure that we do not try to index arrays using index vlaues that are out of bounds. When we set `wraparound` to False, Cython will not support negative indexes, as is the case with Python. While these directives may increase the speed of our code, it can be dangerous; if we do not ensure that we index our arrays properly, it may cause segmentation faults or data corruption.\n",
      "\n",
      "The full set of compiler directives are described in the [Cython docs](http://docs.cython.org/src/reference/compilation.html#compiler-directives)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is the same code using lists instead of NumPy arrays:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython --annotate\n",
      "from libc.math cimport sqrt\n",
      "\n",
      "def euclidean3(list x, list y):\n",
      "    cdef: \n",
      "        double diff\n",
      "        int i\n",
      "    diff = 0\n",
      "    for i in range(len(x)):\n",
      "        diff += (x[i] - y[i])**2\n",
      "    return sqrt(diff)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit euclidean3(np.random.randn(10).tolist(), np.random.randn(10).tolist())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### `pyximport`\n",
      "\n",
      "If we have some Cython source code, we can use `pyximport` to directly import it as if it were a Python module."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyximport\n",
      "\n",
      "# Move source into current directory\n",
      "!cp ../examples/trapezoid.pyx .\n",
      "\n",
      "# Allow it to use Python's import mechanism\n",
      "pyximport.install()\n",
      "\n",
      "from trapezoid import trapez as trapez_pyx\n",
      "trapez_pyx(1, 10, 10) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In other words, it treats `.pyx` files as if they were `.py` files. This includes detecting changes in the source file,, if any, and recompiling it as necessary before importing."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Benchmark example: Gibbs sampling\n",
      "\n",
      "Let's see if we can use Cython to speed up MCMC.\n",
      "\n",
      "Gibbs sampler for function:\n",
      "\n",
      "$$f(x,y) = x x^2 \\exp(-xy^2 - y^2 + 2y - 4x)$$\n",
      "\n",
      "using conditional distributions:\n",
      "    \n",
      "$$x|y \\sim Gamma(3, y^2 +4)$$\n",
      "$$y|x \\sim Normal(\\frac{1}{1+x}, \\frac{1}{2(1+x)})$$\n",
      "\n",
      "Here is the pure Python implementation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import zeros, random, sqrt\n",
      "gamma = random.gamma\n",
      "normal = random.normal\n",
      "\n",
      "def pygibbs(N=20000, thin=200):\n",
      "    mat = zeros((N,2))\n",
      "    x,y = mat[0]\n",
      "    for i in range(N):\n",
      "        for j in range(thin):\n",
      "            x = gamma(3, y**2 + 4)\n",
      "            y = normal(1./(x+1), 1./sqrt(2*(x+1)))\n",
      "        mat[i] = x,y\n",
      "\n",
      "    return mat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit pygibbs(1000, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unchanged, compiling this code with Cython results in a slight improvement in speed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "from numpy import zeros, random, sqrt\n",
      "gamma = random.gamma\n",
      "normal = random.normal\n",
      "\n",
      "def cygibbs(N=20000, thin=200):\n",
      "    mat = zeros((N,2))\n",
      "    x,y = mat[0]\n",
      "    for i in range(N):\n",
      "        for j in range(thin):\n",
      "            x = gamma(3, y**2 + 4)\n",
      "            y = normal(1./(x+1), 1./sqrt(2*(x+1)))\n",
      "        mat[i] = x,y\n",
      "\n",
      "    return mat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit cygibbs(1000, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, for some type declarations:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython\n",
      "from numpy import zeros, random, sqrt\n",
      "from numpy cimport *\n",
      "gamma = random.gamma\n",
      "normal = random.normal\n",
      "\n",
      "def cygibbs2(int N=20000, int thin=200):\n",
      "    cdef: \n",
      "        ndarray[float64_t, ndim=2] mat = zeros((N,2))\n",
      "        float64_t x,y = 0\n",
      "        int i,j\n",
      "    for i in range(N):\n",
      "        for j in range(thin):\n",
      "            x = gamma(3, y**2 + 4)\n",
      "            y = normal(1./(x+1), 1./sqrt(2*(x+1)))\n",
      "        mat[i] = x,y\n",
      "\n",
      "    return mat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit cygibbs2(1000, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A full-blown \"Cythonization\" involves using GSL's random number generators, and giving Cython a few more instructions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If you are using Homebrew on OS X, you can install GSL using \"brew\"\n",
      "! brew install gsl"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%cython -lm -lgsl -lgslcblas\n",
      "\n",
      "cimport cython\n",
      "import numpy as np\n",
      "from numpy cimport *\n",
      "\n",
      "cdef extern from \"math.h\":\n",
      "    double sqrt(double) \n",
      "  \n",
      "cdef extern from \"gsl/gsl_rng.h\":\n",
      "    ctypedef struct gsl_rng_type\n",
      "    ctypedef struct gsl_rng\n",
      "\n",
      "    gsl_rng_type *gsl_rng_mt19937\n",
      "    gsl_rng *gsl_rng_alloc(gsl_rng_type * T) nogil\n",
      "  \n",
      "cdef extern from \"gsl/gsl_randist.h\":\n",
      "    double gamma \"gsl_ran_gamma\"(gsl_rng * r,double,double)\n",
      "    double gaussian \"gsl_ran_gaussian\"(gsl_rng * r,double)\n",
      "  \n",
      "cdef gsl_rng *r = gsl_rng_alloc(gsl_rng_mt19937)\n",
      "\n",
      "@cython.wraparound(False)\n",
      "@cython.boundscheck(False)\n",
      "def gibbs(int N=20000,int thin=500):\n",
      "    cdef: \n",
      "        double x=0\n",
      "        double y=0\n",
      "        int i, j\n",
      "        ndarray[float64_t, ndim=2] samples\n",
      "\n",
      "    samples = np.empty((N,thin))\n",
      "    for i from 0 <= i < N:\n",
      "        for j from 0 <= j < thin:\n",
      "            x = gamma(r,3,1.0/(y*y+4))\n",
      "            y = gaussian(r,1.0/sqrt(x+1))\n",
      "        samples[i,0] = x\n",
      "        samples[i,1] = y\n",
      "    return samples"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit gibbs(1000, 10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise\n",
      "\n",
      "Try using Cython to improve the performance of the gradient descent algorithm from our optimization lecture:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy import optimize\n",
      "\n",
      "def gradient_descent(x0, f, f_prime, adapt=False):\n",
      "    x_i, y_i = x0\n",
      "    all_x_i = list()\n",
      "    all_y_i = list()\n",
      "    all_f_i = list()\n",
      "\n",
      "    for i in range(1, 100):\n",
      "        all_x_i.append(x_i)\n",
      "        all_y_i.append(y_i)\n",
      "        all_f_i.append(f([x_i, y_i]))\n",
      "        dx_i, dy_i = f_prime(np.asarray([x_i, y_i]))\n",
      "        if adapt:\n",
      "            # Compute a step size using a line_search\n",
      "            step = optimize.line_search(f, f_prime,\n",
      "                                np.r_[x_i, y_i], -np.r_[dx_i, dy_i],\n",
      "                                np.r_[dx_i, dy_i], c2=.05)\n",
      "            step = step[0]\n",
      "        else:\n",
      "            step = 1\n",
      "        x_i += -step*dx_i\n",
      "        y_i += -step*dy_i\n",
      "        if np.abs(all_f_i[-1]) < 1e-16:\n",
      "            break\n",
      "    return all_x_i, all_y_i, all_f_i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here is a sample function to optimize. Recall from Section 3 that it returns both the quadratic function and its gradient."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def quad(epsilon, ndim=2):\n",
      "    def f(x):\n",
      "       x = np.asarray(x)\n",
      "       y = x.copy()\n",
      "       y *= np.power(epsilon, np.arange(ndim))\n",
      "       return .33*np.sum(y**2)\n",
      "\n",
      "    def f_prime(x):\n",
      "       x = np.asarray(x)\n",
      "       y = x.copy()\n",
      "       scaling = np.power(epsilon, np.arange(ndim))\n",
      "       y *= scaling\n",
      "       return .33*2*scaling*y\n",
      "\n",
      "    return f, f_prime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Write answer here"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## References\n",
      "\n",
      "[A guide to analyzing Python performance](http://www.huyng.com/posts/python-performance-analysis/)\n",
      "\n",
      "[Kurt Smith's Cython tutorial from SciPy 2013](https://www.youtube.com/watch?v=JKCjsRDffXo)\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}